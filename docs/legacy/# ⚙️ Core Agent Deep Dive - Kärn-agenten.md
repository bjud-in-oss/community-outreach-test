# 丘뙖잺 Core Agent Deep Dive - K칛rn-agenten

## 游꿢 **SYFTE**
Agentens "muskler och hj칛rnstam" - all teknisk komplexitet och orkestrering

## 游 **ARKITEKTUR**
Teknisk implementation av backend-systemet

### **Komponenter:**
- LangChain Orchestration (Agent chains och reasoning)
- **LLM Orchestration Layer** (Centraliserad hantering av Gemini, Groq, etc.)
- LlamaIndex Memory (Semantic RAG f칬r teknisk dokumentation)
- Specialized Tools (Jules, Smolagents, **Composio for external service integrations like Google, GitHub, Vercel**, etc.)
- Decision Engine (AGERA/ADAPTERA/PROCESSA logik)

### **LLM Orchestration Layer:**
K칛rn-agenten agerar som en centraliserad tj칛nst f칬r alla LLM-anrop i systemet. Den hanterar API-nycklar, modellval och prompt-strategier. Andra system, som den Medvetna Agenten, anropar aldrig LLM:er direkt, utan skickar en beg칛ran via `Communication Bridge` som K칛rn-agenten sedan hanterar. Detta s칛kerst칛ller separation, s칛kerhet och underh친llbarhet.

### **Minnesarkitektur Notering:**
Inom ramen f칬r "Multi-Loop, Specialized-RAG"-arkitekturen anv칛nder K칛rn-agenten ett **Semantic RAG** (implementerat med LlamaIndex) f칬r att s칬ka i teknisk data. Detta 칛r i kontrast till den Medvetna Agentens loop, som anv칛nder ett **Graph RAG** f칬r att hantera konversationsminne och relationer.

### **Tool Integration (Composio):**
F칬r att interagera med externa system (b친de v친r interna infrastruktur som **GitHub** och **Vercel**, samt senior-v칛nda tj칛nster som **Google Workspace**) anv칛nder K칛rn-agenten ett centraliserat verktyg som drivs av en self-hosted Composio-instans. Detta abstraherar bort komplexiteten i varje enskilt API och ger agenten en enhetlig, kraftfull "universal-fj칛rrkontroll" f칬r att utf칬ra uppgifter. Detta 칛r avg칬rande f칬r b친de systemets interna DevOps-automatisering och f칬r att kunna utf칬ra tj칛nster 친t seniorer.

### **Planerings- & Exekveringshierarki:**
1.  **Strategisk Planering (Input):** Tar emot `Tasks` fr친n en h칬gre planeringsniv친 (t.ex. EARS-genererade krav fr친n `Senior Cockpit`).
2.  **Taktisk Exekvering (K칛rnan):** Anv칛nder en **ReAct Loop** (Reason-Act-Observe) f칬r att l칬sa en given `Task`.
    -   **Reasoning:** Anv칛nder `LangChain` f칬r att resonera kring uppgiften.
    -   **Acting:** Anv칛nder `Tools` (Jules, Filesystem, etc.) f칬r att utf칬ra handlingar.
    -   **Observing:** Analyserar resultatet av handlingen.
4.  **Minne (Kontext):** Anv칛nder `LlamaIndex RAG` kontinuerligt f칬r att h칛mta relevant kontext och fatta b칛ttre beslut i varje steg av loopen.
5.  **Konceptuell Modell (AGERA/ADAPTERA/PROCESSA):**
    -   **AGERA:** Motsvarar `Act`-steget.
    -   **ADAPTERA:** F칬rm친gan att l칛ra fr친n `Observe`-steget och justera omedelbara handlingar.
    -   **PROCESSA:** Den djupare, sj칛lvf칬rb칛ttrande loopen. En metaprocess som periodiskt analyserar historik fr친n LlamaIndex-minnet f칬r att identifiera m칬nster och f칬resl친 strategiska f칬rb칛ttringar f칬r hela systemet.

## 游늶 **STATUS**
游리 SKAPAS - Beh칬ver implementeras baserat p친 comprehensive tools analysis

## 游댕 **RELATERADE DOKUMENT**
- 01: Master Integration Plan
- 23: Comprehensive Tools Analysis
- 04: Agents Configuration

## 游 **N츿STA STEG**
1. S칛tt upp LangChain orchestration
2. Integrera LlamaIndex memory system
3. Bygg `LLM Orchestration Layer` f칬r att centralisera anrop till Gemini och Groq.
4. Implementera ReAct-loopen (`AGERA/ADAPTERA`) f칬r taktisk exekvering.
5. Skapa den f칬rsta versionen av den sj칛lvf칬rb칛ttrande `PROCESSA`-loopen.